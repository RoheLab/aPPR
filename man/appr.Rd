% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/aPPR.R, R/graph-igraph.R, R/graph-rtweet.R
\name{appr}
\alias{appr}
\alias{appr.igraph}
\alias{appr.rtweet_graph}
\title{Approximate personalized pageranks}
\usage{
appr(
  graph,
  seeds,
  ...,
  alpha = 0.15,
  epsilon = 1e-06,
  tau = NULL,
  max_visits = Inf
)

\method{appr}{igraph}(graph, seeds, ...)

\method{appr}{rtweet_graph}(graph, seeds, ...)
}
\arguments{
\item{graph}{An \code{\link[=abstract_graph]{abstract_graph()}} object, such as that created by
\code{\link[=rtweet_graph]{rtweet_graph()}}. This argument is required.}

\item{seeds}{A character vector of seeds for the personalized pagerank.
The personalized pagerank will return to each of these seeds with
probability \code{alpha} at each node transition. At the moment,
all seeds are given equal weighting. This argument is required.}

\item{...}{Ignored. Passing arguments to \code{...} results in a warning.}

\item{alpha}{Teleportation constant. The teleportation constant is the
probability of returning to a seed node at each node transition.
\code{alpha} must be a valid probabilty; that is, between zero and one.
Defaults to \code{0.15}. This is the inverse of the "dampening factor"
in the original PageRank paper, so \code{alpha = 0.15} corresponds
to a dampening factor of \code{0.85}. Runtime is proportional to
\code{1 / (epsilon * alpha)}, so small \code{alpha} can result in long
runtimes.}

\item{epsilon}{Desired accuracy of approximation. \code{epsilon} must be
a small positive number. Defaults to \code{1e-6}. \code{aPPR} guarantees that
approximated personalized pageranks are uniformly within \code{epsilon} of
their true value. That is, the approximation is guaranteed to be good
in an L-infinity sense. This does not guarantee, however, that
a ranking of nodes by aPPR is close to a ranking of nodes by PPR.

For Twitter graphs, we recommend testing your code with \code{1e-4} or \code{1e-5},
using \code{1e-6} for exploration, and \code{1e-7} to \code{1e-8} for final results,
although these numbers are very rough. It also perfectly reasonable
to run \code{aPPR} for a given number of steps (set via \code{max_visits}),
and then note the approximation accuracy of your results. Internally,
\code{aPPR} keeps a running estimate of achieved accuracy that is always valid.

Anytime you would like to explore more of the graph, you can simply
decrease \code{epsilon}. So you can start with \code{epsilon = 1e-5} and then
gradually decrease \code{epsilon} until you have a sample of the graph
that you are happy with.

Also note that runtime is proportional to \code{1 / (epsilon * alpha)},
so small \code{epsilon} can result in long runtimes.}

\item{tau}{Regularization term. Additionally inflates the in-degree
of each observation by this term by performing the degree
adjustment described in Algorithm 3 and Algorithm 4, which
are described in \code{vignette("Mathematical details")}. Defaults to
\code{NULL}, in which case \code{tau} is set to the average in-degree of
the observed nodes. In general, setting it's reasonable to
set \code{tau} to the average in-degree of the graph.}

\item{max_visits}{Maximum number of unique nodes to visit. Should be a
positive integer. Defaults to \code{Inf}, such that there is no upper bound
on the number of unique nodes to visit. Useful when you want to specify a
fixed amount of computation (or API calls) to use rather than an
error tolerance. We recommend debugging with \code{max_visits ~ 20},
exploration with \code{max_visits} in the hundreds, and \code{max_visits} in the
thousands to ten of thousands for precise results, although this is a
very rough heuristic.}
}
\value{
A \code{\link[=Tracker]{Tracker()}} object. Most relevant is the \code{stats} field,
a \code{\link[tibble:tibble]{tibble::tibble()}} with the following columns:
\itemize{
\item \code{name}: Name of a node (character).
\item \code{p}: Current estimate of residual per out-degree for a node.
\item \code{r}: Estimated error of pagerank estimate for a node.
\item \code{in_degree}: Number of incoming edges to a node.
\item \code{out_degree}: Number of outcoming edges from a node.
\item \code{degree_adjusted}: The personalized pagerank divided by the
node in-degree.
\item \code{regularized}: The personalized pagerank divide by the node
in-degree plus \code{tau}.
}

When computing personalized pageranks for Twitter users (either
via \code{\link[=rtweet_graph]{rtweet_graph()}}, \code{name} is given
as a user ID, not a screen name, regardless of how the seed nodes
were specified.
}
\description{
Computes the personalized pagerank for specified seeds using the
\code{ApproximatePageRank} algorithm of Andersen et al. (2006). Computes
degree-adjustments and degree-regularization of personalized
pagerank vectors as described in Algorithms 3 and 4 of Chen et al. (2019).
These algorithms are randomized; if results are unstable across
multiple runs, decrease \code{epsilon}.
}
\examples{

library(aPPR)
library(igraph)

set.seed(27)

graph <- rtweet_graph()

\dontrun{
appr(graph, "alexpghayes")
}

graph2 <- sample_pa(100)

# this creates a Tracker object
ppr_results <- appr(graph2, seeds = "5")

# the portion of the Tracker object you probably care about
ppr_results$stats

}
\references{
\enumerate{
\item Chen, Fan, Yini Zhang, and Karl Rohe. “Targeted Sampling from Massive Block Model Graphs with Personalized PageRank.” Journal of the Royal Statistical Society: Series B (Statistical Methodology) 82, no. 1 (February 2020): 99–126. https://doi.org/10.1111/rssb.12349.
\item Andersen, Reid, Fan Chung, and Kevin Lang. “Local Graph Partitioning Using PageRank Vectors.” In 2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS’06), 475–86. Berkeley, CA, USA: IEEE, 2006. https://doi.org/10.1109/FOCS.2006.44.
}
}
